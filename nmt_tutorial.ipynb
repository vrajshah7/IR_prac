{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic NMT with Tensorflow seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from matplotlib import pylab\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Seq2Seq Items\n",
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "from tensorflow.python.ops.rnn_cell import LSTMCell\n",
    "from tensorflow.python.ops.rnn_cell import MultiRNNCell\n",
    "from tensorflow.contrib.seq2seq.python.ops import attention_wrapper\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some hyperparameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size= 50000\n",
    "num_units = 128\n",
    "input_size = 128\n",
    "batch_size = 16\n",
    "source_sequence_length=40\n",
    "target_sequence_length=60\n",
    "decoder_type = 'basic' # could be basic or attention\n",
    "sentences_to_read = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source\n",
      "\t [('ausgestattetes', 16818), ('Firmengeschichte', 40229), ('fürchterlichen', 39481), ('Melancholie', 49659), ('Route', 5970), ('Lobbyisten', 11946), ('zuweilen', 9260), ('Computer-', 32843), ('Produktreihe', 27955), ('Nervensystem', 32983)]\n",
      "\t [(0, '<unk>'), (1, '<s>'), (2, '</s>'), (3, ','), (4, '.'), (5, 'die'), (6, 'der'), (7, 'und'), (8, 'in'), (9, 'zu')]\n",
      "\t Vocabulary size:  50000\n",
      "Target\n",
      "\t [('vigour', 16936), ('Markets', 11144), ('screw', 10318), ('Route', 9932), ('Sates', 45188), ('roar', 37596), ('biographical', 29851), ('proportioned', 35062), ('Gozo', 26604), ('base', 1257)]\n",
      "\t [(0, '<unk>'), (1, '<s>'), (2, '</s>'), (3, 'the'), (4, ','), (5, '.'), (6, 'of'), (7, 'and'), (8, 'to'), (9, 'in')]\n",
      "\t Vocabulary size:  50000\n"
     ]
    }
   ],
   "source": [
    "src_dictionary = dict()\n",
    "with open('vocab.50K.de.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        #we are discarding last char as it is new line char\n",
    "        src_dictionary[line[:-1]] = len(src_dictionary)\n",
    "\n",
    "src_reverse_dictionary = dict(zip(src_dictionary.values(),src_dictionary.keys()))\n",
    "\n",
    "print('Source')\n",
    "print('\\t',list(src_dictionary.items())[:10])\n",
    "print('\\t',list(src_reverse_dictionary.items())[:10])\n",
    "print('\\t','Vocabulary size: ', len(src_dictionary))\n",
    "\n",
    "tgt_dictionary = dict()\n",
    "with open('vocab.50K.en.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        #we are discarding last char as it is new line char\n",
    "        tgt_dictionary[line[:-1]] = len(tgt_dictionary)\n",
    "\n",
    "tgt_reverse_dictionary = dict(zip(tgt_dictionary.values(),tgt_dictionary.keys()))\n",
    "\n",
    "print('Target')\n",
    "print('\\t',list(tgt_dictionary.items())[:10])\n",
    "print('\\t',list(tgt_reverse_dictionary.items())[:10])\n",
    "print('\\t','Vocabulary size: ', len(tgt_dictionary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Sentences (English and German)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample translations (50000)\n",
      "( 0 ) DE:  Heute verstehen sich QuarkXPress ® 8 , Photoshop ® und Illustrator ® besser als jemals zuvor . Dank HTML und CSS ­ können Anwender von QuarkXPress inzwischen alle Medien bedienen , und das unabhängig von Anwendungen der Adobe ® Creative Suite ® wie Adobe Flash ® ( SWF ) und Adobe Dreamweaver ® .\n",
      "\n",
      "( 0 ) EN:  Today , QuarkXPress ® 8 has tighter integration with Photoshop ® and Illustrator ® than ever before , and through standards like HTML and CSS , QuarkXPress users can publish across media both independently and alongside Adobe ® Creative Suite ® applications like Adobe Flash ® ( SWF ) and Adobe Dreamweaver ® .\n",
      "\n",
      "( 10000 ) DE:  Es existieren Busverbindungen in nahezu jeden Ort der Provence ( eventuell mit Umsteigen in Aix ##AT##-##AT## en ##AT##-##AT## Provence ) , allerdings sollte beachtet werden , dass die letzten Busse abends ca. um 19 Uhr fahren .\n",
      "\n",
      "( 10000 ) EN:  As always in France those highways are expensive but practical , comfortable and fast .\n",
      "\n",
      "( 20000 ) DE:  Es war staubig , das Bad schmutzig . Sogar die Beleuchtung an der Wand im Flur ( Seitengebäude ) war richtig verstaubt .\n",
      "\n",
      "( 20000 ) EN:  It was rather old fashioned in the decoration .\n",
      "\n",
      "( 30000 ) DE:  Auch ist , so denkt Dr. Gutherz , bereits die erste Seite sehr viel versprechend , da sie eine Definition des klinischen Psychotrauma ##AT##-##AT## Begriffes enthält , der er gänzlich zustimmen kann .\n",
      "\n",
      "( 30000 ) EN:  At the rhetorical climax of this summary , Dr Goodheart comes across some sentences expressed with great pathos .\n",
      "\n",
      "( 40000 ) DE:  Bei einer digitalen Bildkette wird das Intensitätssignal für jedes Pixel ohne analoge Zwischenschritte direkt in der Detektoreinheit digitalisiert , d.h. in Zahlen umgewandelt .\n",
      "\n",
      "( 40000 ) EN:  A digital image chain is an image chain that is equipped with a digital detector instead of an analogue one .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_sent = []\n",
    "target_sent = []\n",
    "\n",
    "test_source_sent = []\n",
    "test_target_sent = []\n",
    "\n",
    "\n",
    "with open('train.de', encoding='utf-8') as f:\n",
    "    for l_i, line in enumerate(f):\n",
    "        # discarding first 20 translations as there was some\n",
    "        # english to english translations found in the first few. which are wrong\n",
    "        if l_i<50:\n",
    "            continue\n",
    "        source_sent.append(line)\n",
    "        if len(source_sent)>=sentences_to_read:\n",
    "            break\n",
    "        \n",
    "            \n",
    "with open('train.en', encoding='utf-8') as f:\n",
    "    for l_i, line in enumerate(f):\n",
    "        if l_i<50:\n",
    "            continue\n",
    "        \n",
    "        target_sent.append(line)\n",
    "        if len(target_sent)>=sentences_to_read:\n",
    "            break\n",
    "        \n",
    "            \n",
    "assert len(source_sent)==len(target_sent),'Source: %d, Target: %d'%(len(source_sent),len(target_sent))\n",
    "\n",
    "print('Sample translations (%d)'%len(source_sent))\n",
    "for i in range(0,sentences_to_read,10000):\n",
    "    print('(',i,') DE: ', source_sent[i])\n",
    "    print('(',i,') EN: ', target_sent[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's analyse some statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Source) Sentence mean length:  26.35934\n",
      "(Source) Sentence stddev length:  13.9681614669\n",
      "(Target) Sentence mean length:  28.58758\n",
      "(Target) Sentence stddev length:  15.1544201388\n"
     ]
    }
   ],
   "source": [
    "def split_to_tokens(sent,is_source):\n",
    "    #sent = sent.replace('-',' ')\n",
    "    sent = sent.replace(',',' ,')\n",
    "    sent = sent.replace('.',' .')\n",
    "    sent = sent.replace('\\n',' ') \n",
    "    \n",
    "    sent_toks = sent.split(' ')\n",
    "    for t_i, tok in enumerate(sent_toks):\n",
    "        if is_source:\n",
    "            if tok not in src_dictionary.keys():\n",
    "                sent_toks[t_i] = '<unk>'\n",
    "        else:\n",
    "            if tok not in tgt_dictionary.keys():\n",
    "                sent_toks[t_i] = '<unk>'\n",
    "    return sent_toks\n",
    "\n",
    "# Let us first look at some statistics of the sentences\n",
    "source_len = []\n",
    "source_mean, source_std = 0,0\n",
    "for sent in source_sent:\n",
    "    source_len.append(len(split_to_tokens(sent,True)))\n",
    "\n",
    "print('(Source) Sentence mean length: ', np.mean(source_len))\n",
    "print('(Source) Sentence stddev length: ', np.std(source_len))\n",
    "\n",
    "target_len = []\n",
    "target_mean, target_std = 0,0\n",
    "for sent in target_sent:\n",
    "    target_len.append(len(split_to_tokens(sent,False)))\n",
    "\n",
    "print('(Target) Sentence mean length: ', np.mean(target_len))\n",
    "print('(Target) Sentence stddev length: ', np.std(target_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the special tokens and make all sentences same length (for batch-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sent lengths:  0\n",
      "Samples from bin\n",
      "\t ['<s>', 'Heute', 'verstehen', 'sich', 'QuarkXPress', '®', '8', '<unk>', ',', 'Photoshop', '®', 'und', 'Illustrator', '®', 'besser', 'als', 'jemals', 'zuvor', '<unk>', '.', 'Dank', 'HTML', 'und', 'CSS', '\\xad', 'können', 'Anwender', 'von', 'QuarkXPress', 'inzwischen', 'alle', 'Medien', 'bedienen', '<unk>', ',', 'und', 'das', 'unabhängig', 'von', 'Anwendungen', 'der']\n",
      "\t ['</s>', 'Today', '<unk>', ',', 'QuarkXPress', '®', '8', 'has', 'tighter', 'integration', 'with', 'Photoshop', '®', 'and', 'Illustrator', '®', 'than', 'ever', 'before', '<unk>', ',', 'and', 'through', 'standards', 'like', 'HTML', 'and', 'CSS', '<unk>', ',', 'QuarkXPress', 'users', 'can', 'publish', 'across', 'media', 'both', 'independently', 'and', 'alongside', 'Adobe', '®', 'Creative', 'Suite', '®', 'applications', 'like', 'Adobe', 'Flash', '®', '(', 'SWF', ')', 'and', 'Adobe', 'Dreamweaver', '®', '<unk>', '.', '<unk>', '</s>']\n",
      "\t ['<s>', 'Erstellen', 'Sie', 'einen', 'Rahmen', 'und', 'gehen', 'Sie', 'dann', 'auf', 'Datei', '&gt;', 'Importieren', '<unk>', '.', '.', '.', 'oder', 'ziehen', 'Sie', 'das', 'Bild', 'einfach', 'per', 'Drag', '&amp;', 'Drop', 'von', 'Ihrem', 'Desktop', '<unk>', ',', 'aus', 'dem', 'Finder', 'oder', 'einer', 'Anwendung', 'wie', 'Adobe', 'Bridge']\n",
      "\t ['</s>', 'Bringing', 'the', 'PSD', 'files', 'into', 'QuarkXPress', 'is', 'the', 'same', 'as', 'any', 'other', 'image', '<unk>', '.', 'Create', 'a', 'Box', 'and', 'then', 'use', 'File', '&gt;', 'Import', '<unk>', '.', '.', '.', 'or', 'simply', 'drag', 'and', 'drop', 'the', 'image', 'from', 'your', 'desktop', '<unk>', ',', 'Finder', 'or', 'an', 'application', 'like', 'Adobe', 'Bridge', '®', 'with', 'or', 'without', 'creating', 'a', 'box', 'first', '<unk>', '.', '<unk>', '</s>', '</s>']\n",
      "\n",
      "\tSentences  50000\n"
     ]
    }
   ],
   "source": [
    "train_inputs = []\n",
    "train_outputs = []\n",
    "train_inp_lengths = []\n",
    "train_out_lengths = []\n",
    "\n",
    "max_tgt_sent_lengths = 0\n",
    "\n",
    "src_max_sent_length = 41\n",
    "tgt_max_sent_length = 61\n",
    "for s_i, (src_sent, tgt_sent) in enumerate(zip(source_sent,target_sent)):\n",
    "    \n",
    "    src_sent_tokens = split_to_tokens(src_sent,True)\n",
    "    tgt_sent_tokens = split_to_tokens(tgt_sent,False)\n",
    "        \n",
    "    num_src_sent = []\n",
    "    for tok in src_sent_tokens:\n",
    "        num_src_sent.append(src_dictionary[tok])\n",
    "\n",
    "    num_src_set = num_src_sent[::-1] # we reverse the source sentence. This improves performance\n",
    "    num_src_sent.insert(0,src_dictionary['<s>'])\n",
    "    train_inp_lengths.append(min(len(num_src_sent)+1,src_max_sent_length))\n",
    "    \n",
    "    # append until the sentence reaches max length\n",
    "    if len(num_src_sent)<src_max_sent_length:\n",
    "        num_src_sent.extend([src_dictionary['</s>'] for _ in range(src_max_sent_length - len(num_src_sent))])\n",
    "    # if more than max length, truncate the sentence\n",
    "    elif len(num_src_sent)>src_max_sent_length:\n",
    "        num_src_sent = num_src_sent[:src_max_sent_length]\n",
    "    assert len(num_src_sent)==src_max_sent_length,len(num_src_sent)\n",
    "\n",
    "    train_inputs.append(num_src_sent)\n",
    "\n",
    "    num_tgt_sent = [tgt_dictionary['</s>']]\n",
    "    for tok in tgt_sent_tokens:\n",
    "        num_tgt_sent.append(tgt_dictionary[tok])\n",
    "    \n",
    "    train_out_lengths.append(min(len(num_tgt_sent)+1,tgt_max_sent_length))\n",
    "    \n",
    "    if len(num_tgt_sent)<tgt_max_sent_length:\n",
    "        num_tgt_sent.extend([tgt_dictionary['</s>'] for _ in range(tgt_max_sent_length - len(num_tgt_sent))])\n",
    "    elif len(num_tgt_sent)>tgt_max_sent_length:\n",
    "        num_tgt_sent = num_tgt_sent[:tgt_max_sent_length]\n",
    "    \n",
    "    train_outputs.append(num_tgt_sent)\n",
    "    assert len(train_outputs[s_i])==tgt_max_sent_length, 'Sent length needs to be 60, but is %d'%len(binned_outputs[s_i])    \n",
    "\n",
    "assert len(train_inputs)  == len(source_sent),\\\n",
    "        'Size of total bin elements: %d, Total sentences: %d'\\\n",
    "                %(len(train_inputs),len(source_sent))\n",
    "\n",
    "print('Max sent lengths: ', max_tgt_sent_lengths)\n",
    "\n",
    "\n",
    "train_inputs = np.array(train_inputs, dtype=np.int32)\n",
    "train_outputs = np.array(train_outputs, dtype=np.int32)\n",
    "train_inp_lengths = np.array(train_inp_lengths, dtype=np.int32)\n",
    "train_out_lengths = np.array(train_out_lengths, dtype=np.int32)\n",
    "print('Samples from bin')\n",
    "print('\\t',[src_reverse_dictionary[w]  for w in train_inputs[0,:].tolist()])\n",
    "print('\\t',[tgt_reverse_dictionary[w]  for w in train_outputs[0,:].tolist()])\n",
    "print('\\t',[src_reverse_dictionary[w]  for w in train_inputs[10,:].tolist()])\n",
    "print('\\t',[tgt_reverse_dictionary[w]  for w in train_outputs[10,:].tolist()])\n",
    "print()\n",
    "print('\\tSentences ',train_inputs.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Data Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source data\n",
      "['Heute', 'Hier', 'Sie', 'Häufig', 'In']\n",
      "['verstehen', 'erfahren', 'werden', 'wird', 'diesem']\n",
      "['sich', 'Sie', 'überrascht', 'die', 'Abschnitt']\n",
      "['QuarkXPress', '<unk>', 'sein', 'Meinung', 'erläutern']\n",
      "['®', ',', '<unk>', 'vertreten', 'wir']\n",
      "['8', 'wie', ',', '<unk>', '<unk>']\n",
      "['<unk>', 'Sie', 'wie', ',', ',']\n",
      "[',', 'Creative', 'einfach', 'dass', 'wann']\n",
      "['Photoshop', 'Suite', 'sich', 'QuarkXPress', 'Sie']\n",
      "['®', '2', 'mit', '8', 'für']\n",
      "['und', 'und', 'Quark', 'von', 'Ihre']\n",
      "['Illustrator', 'Creative', 'das', 'allen', 'Bilder']\n",
      "['®', 'Suite', 'volle', 'heute', 'das']\n",
      "['besser', '3', 'Potenzial', 'verfügbaren', 'PSD']\n",
      "['als', 'am', 'Ihrer', 'Layout', '##AT##-##AT##']\n",
      "['jemals', 'besten', 'Design', '##AT##-##AT##', 'Format']\n",
      "['zuvor', 'zusammen', '##AT##-##AT##', 'Programmen', 'verwenden']\n",
      "['<unk>', 'mit', 'Software', 'die', 'sollten']\n",
      "['.', 'QuarkXPress', 'erschließen', 'beste', 'und']\n",
      "['Dank', 'nutzen', 'lässt', 'Integration', 'wie']\n",
      "['HTML', 'können', '<unk>', 'mit', 'Sie']\n",
      "['und', '<unk>', '.', 'Photoshop', 'es']\n",
      "['CSS', '.', '<unk>', 'über', 'für']\n",
      "['\\xad', '<unk>', '</s>', 'das', 'Ihre']\n",
      "['können', '</s>', '</s>', 'PSD', 'Bilder']\n",
      "['Anwender', '</s>', '</s>', '##AT##-##AT##', 'optimal']\n",
      "['von', '</s>', '</s>', 'Dateiformat', 'nutzen']\n",
      "['QuarkXPress', '</s>', '</s>', 'bietet', '<unk>']\n",
      "['inzwischen', '</s>', '</s>', '<unk>', '.']\n",
      "['alle', '</s>', '</s>', '.', '<unk>']\n",
      "['Medien', '</s>', '</s>', '<unk>', '</s>']\n",
      "['bedienen', '</s>', '</s>', '</s>', '</s>']\n",
      "['<unk>', '</s>', '</s>', '</s>', '</s>']\n",
      "[',', '</s>', '</s>', '</s>', '</s>']\n",
      "['und', '</s>', '</s>', '</s>', '</s>']\n",
      "['das', '</s>', '</s>', '</s>', '</s>']\n",
      "['unabhängig', '</s>', '</s>', '</s>', '</s>']\n",
      "['von', '</s>', '</s>', '</s>', '</s>']\n",
      "['Anwendungen', '</s>', '</s>', '</s>', '</s>']\n",
      "['der', '</s>', '</s>', '</s>', '</s>']\n",
      "\n",
      "Target data batch (first time)\n",
      "['Today', 'You', 'QuarkXPress', 'In', 'For']\n",
      "['<unk>', '’', '8', 'this', 'example']\n",
      "[',', 'll', 'is', 'section', '<unk>']\n",
      "['QuarkXPress', 'be', 'considered', 'we', ',']\n",
      "['®', 'surprised', 'by', '’', 'you']\n",
      "['8', 'how', 'many', 'll', 'may']\n",
      "['has', 'easy', 'to', 'explain', 'have']\n",
      "['tighter', 'Quark', 'have', 'when', 'multiple']\n",
      "['integration', 'has', 'the', 'you', 'layers']\n",
      "['with', 'made', 'best', 'should', 'in']\n",
      "['Photoshop', 'it', 'integration', 'use', 'your']\n",
      "['®', 'to', 'with', 'the', 'PSD']\n",
      "['and', 'unlock', 'Photoshop', 'PSD', 'with']\n",
      "['Illustrator', 'the', '’', 'format', 'different']\n",
      "['®', 'full', 's', 'for', 'product']\n",
      "['than', 'potential', 'PSD', 'your', 'shots']\n",
      "['ever', 'of', 'file', 'images', '<unk>']\n",
      "['before', 'all', 'format', 'and', ',']\n",
      "['<unk>', 'your', 'of', 'how', 'which']\n",
      "[',', 'design', 'any', 'to', 'will']\n",
      "['and', 'software', 'layout', 'get', 'vary']\n",
      "['through', '<unk>', 'tool', 'the', 'from']\n",
      "['standards', '.', 'available', 'most', 'publication']\n",
      "['like', '<unk>', 'today', 'out', 'to']\n",
      "['HTML', '</s>', '<unk>', 'of', 'publication']\n",
      "['and', '</s>', '.', 'them', '<unk>']\n",
      "['CSS', '</s>', '<unk>', '<unk>', '.']\n",
      "['<unk>', '</s>', '</s>', '.', '<unk>']\n",
      "[',', '</s>', '</s>', '<unk>', '</s>']\n",
      "['QuarkXPress', '</s>', '</s>', '</s>', '</s>']\n",
      "['users', '</s>', '</s>', '</s>', '</s>']\n",
      "['can', '</s>', '</s>', '</s>', '</s>']\n",
      "['publish', '</s>', '</s>', '</s>', '</s>']\n",
      "['across', '</s>', '</s>', '</s>', '</s>']\n",
      "['media', '</s>', '</s>', '</s>', '</s>']\n",
      "['both', '</s>', '</s>', '</s>', '</s>']\n",
      "['independently', '</s>', '</s>', '</s>', '</s>']\n",
      "['and', '</s>', '</s>', '</s>', '</s>']\n",
      "['alongside', '</s>', '</s>', '</s>', '</s>']\n",
      "['Adobe', '</s>', '</s>', '</s>', '</s>']\n",
      "['®', '</s>', '</s>', '</s>', '</s>']\n",
      "['Creative', '</s>', '</s>', '</s>', '</s>']\n",
      "['Suite', '</s>', '</s>', '</s>', '</s>']\n",
      "['®', '</s>', '</s>', '</s>', '</s>']\n",
      "['applications', '</s>', '</s>', '</s>', '</s>']\n",
      "['like', '</s>', '</s>', '</s>', '</s>']\n",
      "['Adobe', '</s>', '</s>', '</s>', '</s>']\n",
      "['Flash', '</s>', '</s>', '</s>', '</s>']\n",
      "['®', '</s>', '</s>', '</s>', '</s>']\n",
      "['(', '</s>', '</s>', '</s>', '</s>']\n",
      "['SWF', '</s>', '</s>', '</s>', '</s>']\n",
      "[')', '</s>', '</s>', '</s>', '</s>']\n",
      "['and', '</s>', '</s>', '</s>', '</s>']\n",
      "['Adobe', '</s>', '</s>', '</s>', '</s>']\n",
      "['Dreamweaver', '</s>', '</s>', '</s>', '</s>']\n",
      "['®', '</s>', '</s>', '</s>', '</s>']\n",
      "['<unk>', '</s>', '</s>', '</s>', '</s>']\n",
      "['.', '</s>', '</s>', '</s>', '</s>']\n",
      "['<unk>', '</s>', '</s>', '</s>', '</s>']\n",
      "['</s>', '</s>', '</s>', '</s>', '</s>']\n",
      "\n",
      "Target data batch (non-first time)\n",
      "['Today', 'You', 'QuarkXPress', 'In', 'For']\n",
      "['<unk>', '’', '8', 'this', 'example']\n",
      "[',', 'll', 'is', 'section', '<unk>']\n",
      "['QuarkXPress', 'be', 'considered', 'we', ',']\n",
      "['®', 'surprised', 'by', '’', 'you']\n",
      "['8', 'how', 'many', 'll', 'may']\n",
      "['has', 'easy', 'to', 'explain', 'have']\n",
      "['tighter', 'Quark', 'have', 'when', 'multiple']\n",
      "['integration', 'has', 'the', 'you', 'layers']\n",
      "['with', 'made', 'best', 'should', 'in']\n",
      "['Photoshop', 'it', 'integration', 'use', 'your']\n",
      "['®', 'to', 'with', 'the', 'PSD']\n",
      "['and', 'unlock', 'Photoshop', 'PSD', 'with']\n",
      "['Illustrator', 'the', '’', 'format', 'different']\n",
      "['®', 'full', 's', 'for', 'product']\n",
      "['than', 'potential', 'PSD', 'your', 'shots']\n",
      "['ever', 'of', 'file', 'images', '<unk>']\n",
      "['before', 'all', 'format', 'and', ',']\n",
      "['<unk>', 'your', 'of', 'how', 'which']\n",
      "[',', 'design', 'any', 'to', 'will']\n",
      "['and', 'software', 'layout', 'get', 'vary']\n",
      "['through', '<unk>', 'tool', 'the', 'from']\n",
      "['standards', '.', 'available', 'most', 'publication']\n",
      "['like', '<unk>', 'today', 'out', 'to']\n",
      "['HTML', '</s>', '<unk>', 'of', 'publication']\n",
      "['and', '</s>', '.', 'them', '<unk>']\n",
      "['CSS', '</s>', '<unk>', '<unk>', '.']\n",
      "['<unk>', '</s>', '</s>', '.', '<unk>']\n",
      "[',', '</s>', '</s>', '<unk>', '</s>']\n",
      "['QuarkXPress', '</s>', '</s>', '</s>', '</s>']\n",
      "['users', '</s>', '</s>', '</s>', '</s>']\n",
      "['can', '</s>', '</s>', '</s>', '</s>']\n",
      "['publish', '</s>', '</s>', '</s>', '</s>']\n",
      "['across', '</s>', '</s>', '</s>', '</s>']\n",
      "['media', '</s>', '</s>', '</s>', '</s>']\n",
      "['both', '</s>', '</s>', '</s>', '</s>']\n",
      "['independently', '</s>', '</s>', '</s>', '</s>']\n",
      "['and', '</s>', '</s>', '</s>', '</s>']\n",
      "['alongside', '</s>', '</s>', '</s>', '</s>']\n",
      "['Adobe', '</s>', '</s>', '</s>', '</s>']\n",
      "['®', '</s>', '</s>', '</s>', '</s>']\n",
      "['Creative', '</s>', '</s>', '</s>', '</s>']\n",
      "['Suite', '</s>', '</s>', '</s>', '</s>']\n",
      "['®', '</s>', '</s>', '</s>', '</s>']\n",
      "['applications', '</s>', '</s>', '</s>', '</s>']\n",
      "['like', '</s>', '</s>', '</s>', '</s>']\n",
      "['Adobe', '</s>', '</s>', '</s>', '</s>']\n",
      "['Flash', '</s>', '</s>', '</s>', '</s>']\n",
      "['®', '</s>', '</s>', '</s>', '</s>']\n",
      "['(', '</s>', '</s>', '</s>', '</s>']\n",
      "['SWF', '</s>', '</s>', '</s>', '</s>']\n",
      "[')', '</s>', '</s>', '</s>', '</s>']\n",
      "['and', '</s>', '</s>', '</s>', '</s>']\n",
      "['Adobe', '</s>', '</s>', '</s>', '</s>']\n",
      "['Dreamweaver', '</s>', '</s>', '</s>', '</s>']\n",
      "['®', '</s>', '</s>', '</s>', '</s>']\n",
      "['<unk>', '</s>', '</s>', '</s>', '</s>']\n",
      "['.', '</s>', '</s>', '</s>', '</s>']\n",
      "['<unk>', '</s>', '</s>', '</s>', '</s>']\n",
      "['</s>', '</s>', '</s>', '</s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "input_size = 128\n",
    "\n",
    "class DataGeneratorMT(object):\n",
    "    \n",
    "    def __init__(self,batch_size,num_unroll,is_source):\n",
    "        self._batch_size = batch_size\n",
    "        self._num_unroll = num_unroll\n",
    "        self._cursor = [0 for offset in range(self._batch_size)]\n",
    "        \n",
    "        \n",
    "        self._src_word_embeddings = np.load('de-embeddings.npy')\n",
    "        \n",
    "        self._tgt_word_embeddings = np.load('en-embeddings.npy')\n",
    "        \n",
    "        self._sent_ids = None\n",
    "        \n",
    "        self._is_source = is_source\n",
    "        \n",
    "                \n",
    "    def next_batch(self, sent_ids, first_set):\n",
    "        \n",
    "        if self._is_source:\n",
    "            max_sent_length = src_max_sent_length\n",
    "        else:\n",
    "            max_sent_length = tgt_max_sent_length\n",
    "        batch_labels_ind = []\n",
    "        batch_data = np.zeros((self._batch_size),dtype=np.float32)\n",
    "        batch_labels = np.zeros((self._batch_size),dtype=np.float32)\n",
    "        \n",
    "        for b in range(self._batch_size):\n",
    "            \n",
    "            sent_id = sent_ids[b]\n",
    "            \n",
    "            if self._is_source:\n",
    "                sent_text = train_inputs[sent_id]\n",
    "                             \n",
    "                batch_data[b] = sent_text[self._cursor[b]]\n",
    "                batch_labels[b]=sent_text[self._cursor[b]+1]\n",
    "\n",
    "            else:\n",
    "                sent_text = train_outputs[sent_id]\n",
    "                \n",
    "                batch_data[b] = sent_text[self._cursor[b]]\n",
    "                batch_labels[b] = sent_text[self._cursor[b]+1]\n",
    "\n",
    "            self._cursor[b] = (self._cursor[b]+1)%(max_sent_length-1)\n",
    "                                    \n",
    "        return batch_data,batch_labels\n",
    "        \n",
    "    def unroll_batches(self,sent_ids):\n",
    "        \n",
    "        if sent_ids is not None:\n",
    "            \n",
    "            self._sent_ids = sent_ids\n",
    "            \n",
    "            self._cursor = [0 for _ in range(self._batch_size)]\n",
    "                \n",
    "        unroll_data,unroll_labels = [],[]\n",
    "        inp_lengths = None\n",
    "        for ui in range(self._num_unroll):\n",
    "            \n",
    "            data, labels = self.next_batch(self._sent_ids, False)\n",
    "                    \n",
    "            unroll_data.append(data)\n",
    "            unroll_labels.append(labels)\n",
    "            inp_lengths = train_inp_lengths[sent_ids]\n",
    "        return unroll_data, unroll_labels, self._sent_ids, inp_lengths\n",
    "    \n",
    "    def reset_indices(self):\n",
    "        self._cursor = [0 for offset in range(self._batch_size)]\n",
    "        \n",
    "# Running a tiny set to see if the implementation correct\n",
    "dg = DataGeneratorMT(batch_size=5,num_unroll=40,is_source=True)\n",
    "u_data, u_labels, _, _ = dg.unroll_batches([0,1,2,3,4])\n",
    "\n",
    "print('Source data')\n",
    "for _, lbl in zip(u_data,u_labels):\n",
    "    print([src_reverse_dictionary[w] for w in lbl.tolist()])\n",
    "\n",
    "        \n",
    "# Running a tiny set to see if the implementation correct\n",
    "dg = DataGeneratorMT(batch_size=5,num_unroll=60,is_source=False)\n",
    "u_data, u_labels, _, _ = dg.unroll_batches([0,2,3,4,5])\n",
    "print('\\nTarget data batch (first time)')\n",
    "for d_i,(_, lbl) in enumerate(zip(u_data,u_labels)):\n",
    "    #if d_i>5 and d_i < 35:\n",
    "    #    continue\n",
    "\n",
    "    print([tgt_reverse_dictionary[w] for w in lbl.tolist()])\n",
    "\n",
    "print('\\nTarget data batch (non-first time)')\n",
    "u_data, u_labels, _, _ = dg.unroll_batches(None)\n",
    "for d_i,(_, lbl) in enumerate(zip(u_data,u_labels)):\n",
    "    \n",
    "    #if d_i>5 and d_i < 35:\n",
    "    #    continue\n",
    "        \n",
    "    print([tgt_reverse_dictionary[w] for w in lbl.tolist()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs Outputs Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "enc_train_inputs = []\n",
    "dec_train_inputs = []\n",
    "\n",
    "# Need to use pre-trained word embeddings\n",
    "encoder_emb_layer = tf.convert_to_tensor(np.load('de-embeddings.npy'))\n",
    "decoder_emb_layer = tf.convert_to_tensor(np.load('en-embeddings.npy'))\n",
    "\n",
    "# Defining unrolled training inputs\n",
    "for ui in range(source_sequence_length):\n",
    "    enc_train_inputs.append(tf.placeholder(tf.int32, shape=[batch_size],name='enc_train_inputs_%d'%ui))\n",
    "\n",
    "dec_train_labels=[]\n",
    "dec_label_masks = []\n",
    "for ui in range(target_sequence_length):\n",
    "    dec_train_inputs.append(tf.placeholder(tf.int32, shape=[batch_size],name='dec_train_inputs_%d'%ui))\n",
    "    dec_train_labels.append(tf.placeholder(tf.int32, shape=[batch_size],name='dec-train_outputs_%d'%ui))\n",
    "    dec_label_masks.append(tf.placeholder(tf.float32, shape=[batch_size],name='dec-label_masks_%d'%ui))\n",
    "    \n",
    "encoder_emb_inp = [tf.nn.embedding_lookup(encoder_emb_layer, src) for src in enc_train_inputs]\n",
    "encoder_emb_inp = tf.stack(encoder_emb_inp)\n",
    "\n",
    "decoder_emb_inp = [tf.nn.embedding_lookup(decoder_emb_layer, src) for src in dec_train_inputs]\n",
    "decoder_emb_inp = tf.stack(decoder_emb_inp)\n",
    "\n",
    "enc_train_inp_lengths = tf.placeholder(tf.int32, shape=[batch_size],name='train_input_lengths')\n",
    "dec_train_inp_lengths = tf.placeholder(tf.int32, shape=[batch_size],name='train_output_lengths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "\n",
    "initial_state = encoder_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encoder_emb_inp, initial_state=initial_state,\n",
    "    sequence_length=enc_train_inp_lengths, \n",
    "    time_major=True, swap_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build RNN cell\n",
    "decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "\n",
    "projection_layer = Dense(units=vocab_size, use_bias=True)\n",
    "\n",
    "# Helper\n",
    "helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "    decoder_emb_inp, [tgt_max_sent_length-1 for _ in range(batch_size)], time_major=True)\n",
    "\n",
    "# Decoder\n",
    "if decoder_type == 'basic':\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        decoder_cell, helper, encoder_state,\n",
    "        output_layer=projection_layer)\n",
    "    \n",
    "elif decoder_type == 'attention':\n",
    "    decoder = tf.contrib.seq2seq.BahdanauAttention(\n",
    "        decoder_cell, helper, encoder_state,\n",
    "        output_layer=projection_layer)\n",
    "    \n",
    "# Dynamic decoding\n",
    "outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "    decoder, output_time_major=True,\n",
    "    swap_memory=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = outputs.rnn_output\n",
    "\n",
    "crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=dec_train_labels, logits=logits)\n",
    "loss = (tf.reduce_sum(crossent*tf.stack(dec_label_masks)) / (batch_size*target_sequence_length))\n",
    "\n",
    "train_prediction = outputs.sample_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Optimizer with Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining Optimizer\n"
     ]
    }
   ],
   "source": [
    "print('Defining Optimizer')\n",
    "# Adam Optimizer. And gradient clipping.\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "inc_gstep = tf.assign(global_step,global_step + 1)\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    0.01, global_step, decay_steps=10, decay_rate=0.9, staircase=True)\n",
    "\n",
    "with tf.variable_scope('Adam'):\n",
    "    adam_optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "adam_gradients, v = zip(*adam_optimizer.compute_gradients(loss))\n",
    "adam_gradients, _ = tf.clip_by_global_norm(adam_gradients, 25.0)\n",
    "adam_optimize = adam_optimizer.apply_gradients(zip(adam_gradients, v))\n",
    "\n",
    "with tf.variable_scope('SGD'):\n",
    "    sgd_optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "sgd_gradients, v = zip(*sgd_optimizer.compute_gradients(loss))\n",
    "sgd_gradients, _ = tf.clip_by_global_norm(sgd_gradients, 25.0)\n",
    "sgd_optimize = sgd_optimizer.apply_gradients(zip(sgd_gradients, v))\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the NMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  250\n",
      "Actual: Any person can choose to not make use of them <unk> , but may also choose to make use of all of them <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> <unk> the <unk> the the the the the <unk> , the <unk> <unk> <unk> <unk> the the <unk> the <unk> the <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: The more elements on the page <unk> , the less trivial this task becomes <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> is of the <unk> <unk> , the <unk> <unk> <unk> <unk> <unk> the . <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  500\n",
      "Actual: A selection of executive rooms provide stunning views of the Houses of Parliament <unk> , Big Ben and many other London landmarks <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> of the <unk> <unk> a <unk> of the <unk> <unk> the <unk> , and <unk> <unk> the <unk> <unk> <unk> <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: We set out 10 years ago to help companies find their way in today &apos;s information overload <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The can to of <unk> <unk> <unk> the the <unk> the <unk> <unk> the <unk> <unk> <unk> <unk> . <unk> </s> \n",
      "\n",
      "============= Step  500  =============\n",
      "\t Loss:  2.55195643544\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  750\n",
      "Actual: 4 His family consisting of eleven souls <unk> , namely <unk> , my father <unk> , Joseph Smith ; my a mother <unk> , Lucy Smith ( whose name <unk> , previous to her marriage <unk> , was Mack <unk> , daughter of Solomon Mack ) ; my brothers <unk> , b <unk> ( who died November 19th <unk> , \n",
      "\n",
      "Predicted: The And <unk> is of the <unk> <unk> , the <unk> , <unk> <unk> <unk> , the <unk> <unk> the <unk> <unk> <unk> , and <unk> <unk> <unk> <unk> <unk> , and the the <unk> <unk> . and a <unk> . and <unk> the <unk> <unk> <unk> <unk> <unk> <unk> . and <unk> <unk> <unk> <unk> <unk> <unk> <unk> . \n",
      "\n",
      "\n",
      "Actual: <unk> � das <unk> � s is situated in the most beautiful part of Algarve ( Portugal ) <unk> , directly on the &quot; Boa Vista &quot; golf course in Lagos <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> <unk> <unk> <unk> <unk> <unk> a in the <unk> of of of the <unk> <unk> <unk> <unk> . <unk> to the <unk> <unk> <unk> <unk> <unk> <unk> <unk> the <unk> . <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  1000\n",
      "Actual: When in Rome <unk> , being close to Termini is a great help in finding your way around <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The you the <unk> , the in to the <unk> a great location to the the <unk> <unk> the . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: Have a look at the extensive information in the travel guide section and familiarise yourself with the surroundings <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The a <unk> at the <unk> of of the <unk> of to <unk> the a to a <unk> of . <unk> </s> \n",
      "\n",
      "============= Step  1000  =============\n",
      "\t Loss:  2.12460603571\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  1250\n",
      "Actual: One of the distinguishing features of Data Wizard for MySQL consists in the ability to schedule tasks for executing them ( once or periodically ) later <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The of the <unk> of of the ##AT##-##AT## <unk> the <unk> of the <unk> to the the <unk> the <unk> <unk> <unk> ) the the <unk> <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: Gay Provence brings you a new experience in traveling with its gay and lesbian members sharing their love and knowledge of their country <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> <unk> the to great ##AT##-##AT## of the <unk> the own <unk> the <unk> <unk> <unk> own <unk> the of the own <unk> . <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  1500\n",
      "Actual: Of course I also offer hosting of <unk> Pro on one of the fast and reliable dedicated <unk> servers <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The course of <unk> have the the the <unk> <unk> the of the <unk> <unk> <unk> <unk> to . <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: Consisting of 2 modern buildings with simple <unk> , wooden balconies and set in a large private garden <unk> , our nicely renovated 3 ##AT##-##AT## star boarding house is located in Budapest &apos;s green belt <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The of the <unk> <unk> <unk> a access , and and <unk> the in the quiet village area <unk> , the hotel <unk> <unk> ##AT##-##AT## star hotel <unk> <unk> located in the <unk> <unk> <unk> <unk> . <unk> </s> \n",
      "\n",
      "============= Step  1500  =============\n",
      "\t Loss:  1.99418069172\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  1750\n",
      "Actual: There are many Cadiz apartments for rent around the city <unk> . <unk> . . . <unk> </s> \n",
      "\n",
      "Predicted: The are a of <unk> in the in the hotel centre . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: To view generated API documentation with embedded UML class diagrams in SVG format <unk> , your browser requires a SVG plugin <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The the the the <unk> <unk> a <unk> <unk> <unk> <unk> the <unk> <unk> , and <unk> <unk> the new <unk> <unk> , <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  2000\n",
      "Actual: Arguments passed in this way should be in the order in which they are defined in the constructor <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> to the hotel to be a the <unk> to the <unk> have not by the <unk> <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: In the bottom of the box were laid two stones <unk> of the box <unk> , and on these stones lay the plates and the other things with them <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The the <unk> of the <unk> <unk> a by <unk> <unk> , the <unk> <unk> , the the the things <unk> <unk> <unk> of the <unk> <unk> <unk> the <unk> . <unk> </s> \n",
      "\n",
      "============= Step  2000  =============\n",
      "\t Loss:  1.92033474255\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  2250\n",
      "Actual: The streets are blocked so cars are not <unk> . . . <unk> </s> \n",
      "\n",
      "Predicted: The hotel of the <unk> <unk> <unk> not <unk> , <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: The hotel kindly requests that you leave your car keys with the reception in case it needs to be moved <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> is is are are can the <unk> <unk> <unk> the <unk> <unk> the <unk> <unk> <unk> stay a <unk> . <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  2500\n",
      "Actual: The hotel features 5 conference rooms which can hold up to 180 people <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The hotel is a ##AT##-##AT## rooms <unk> are be a to the ##AT##-##AT## <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: You are in search of international perspectives <unk> , diversified clients <unk> , excellent career opportunities and highly motivated colleagues ? <unk> </s> \n",
      "\n",
      "Predicted: The can available the for the <unk> <unk> , and <unk> <unk> , and <unk> <unk> <unk> the <unk> <unk> <unk> <unk> </s> \n",
      "\n",
      "============= Step  2500  =============\n",
      "\t Loss:  1.85549543881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  2750\n",
      "Actual: Room Notes : Sea View Room - A 2 <unk> % charge will be added to your final account if payment is made by Credit / Debit Card <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The Notes : Our <unk> Hotel in 2 24 <unk> <unk> <unk> of be charged to the stay day <unk> you <unk> available <unk> the <unk> <unk> <unk> <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: <unk> : 20 x 1 <unk> / 2 <unk> Inch <unk> - <unk> - Pink ! <unk> </s> \n",
      "\n",
      "Predicted: The <unk> <unk> <unk> <unk> <unk> , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> Service <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  3000\n",
      "Actual: The nearest public transport stop <unk> , such as bus <unk> , metro or tram <unk> , is also given in the “ neighbourhood and location ” description for each apartment <unk> , to help you locate the apartment with ease <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> to transport is is , <unk> as the <unk> , and <unk> <unk> <unk> , and a a in the heart <unk> &quot; the <unk> <unk> of the <unk> <unk> , and the you to your <unk> <unk> a <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: has support for filter chains <unk> , allowing you to specify multiple <unk> , sequential filters <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The a for the <unk> <unk> , and you to the the <unk> . and <unk> <unk> , <unk> </s> \n",
      "\n",
      "============= Step  3000  =============\n",
      "\t Loss:  1.81006903219\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  3250\n",
      "Actual: Over 4 <unk> standard transducers including contact <unk> , immersion <unk> , angle beam <unk> , and single / multi ##AT##-##AT## element probes for virtually all flaw and thickness inspection applications <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> <unk> , <unk> <unk> the <unk> , and <unk> , and <unk> <unk> , and <unk> / <unk> ##AT##-##AT## ray <unk> <unk> a <unk> <unk> <unk> the <unk> <unk> <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: One bedroom and studios &#124; Flats with two bedrooms &#124; Three or more rooms &#124; Houses and Villas &#124; Hotels &#124; Hostels &#124; Rural Homes &#124; Last Minute Offers ! <unk> </s> \n",
      "\n",
      "Predicted: The of with the <unk> <unk> &#124; a bedrooms <unk> <unk> <unk> Twin <unk> <unk> <unk> &#124; Breakfast &#124; Hotels &#124; Hotels &#124; Hotels &#124; &#124; Last Minute Offers ! <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  3500\n",
      "Actual: A <unk> server typically has one process ( the parent ) which coordinates a set of processes ( its children ) who actually do the work of serving up web pages <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The credit <unk> <unk> is a of <unk> <unk> <unk> ) <unk> is the <unk> of the <unk> <unk> <unk> ) <unk> are the not <unk> of the <unk> to <unk> <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: Private parking is possible at a location nearby and costs EUR 25 <unk> per day <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The parking is possible on the location nearby and costs EUR 6 <unk> per day <unk> . <unk> </s> \n",
      "\n",
      "============= Step  3500  =============\n",
      "\t Loss:  1.80698282361\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  3750\n",
      "Actual: We offer 311 rooms in Maritime <unk> , Scandinavian and Italian design styles <unk> , each style invoking a different time and place <unk> , all rooms comfortable and well equipped <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The have the our and the and , and and modern <unk> <unk> <unk> . and of ##AT##-##AT## <unk> hotel <unk> of a <unk> . and of are <unk> a ##AT##-##AT## <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: All orders are processed by our partner share ##STAR## it ! <unk> </s> \n",
      "\n",
      "Predicted: <unk> children are available in the customers and <unk> <unk> <unk> <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  4000\n",
      "Actual: Normally the first drink is free <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The the <unk> thing in a of . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: <unk> ’ s location and modern amenities make it a great choice for the contemporary traveler <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> s <unk> is the <unk> <unk> a a few choice for a hotel and <unk> . <unk> </s> \n",
      "\n",
      "============= Step  4000  =============\n",
      "\t Loss:  1.76541591763\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  4250\n",
      "Actual: The hotel benefits from a privileged location at once away from the hustle and bustle of the city and close to the city centre and beaches <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> is from the total location in the the from the city <unk> the of the city <unk> the to the city centre <unk> the <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: We could hear the noise from the street a lot <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The were have the <unk> of the <unk> <unk> <unk> of . <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  4500\n",
      "Actual: The <unk> House Hotel has undergone extensive external and internal refurbishment since 2001 <unk> . Great care has been taken to preserve and re ##AT##-##AT## discover the oak beams <unk> , <unk> fires <unk> , and all the original and unique features <unk> , which make this Grade I listed building so full of character and charm <unk> . <unk> \n",
      "\n",
      "Predicted: The hotel is is is a exceptional <unk> service the rates <unk> the <unk> , <unk> <unk> to been a in the the the ##AT##-##AT## postcard the <unk> <unk> and . and <unk> <unk> , and the the <unk> <unk> <unk> design <unk> . and is the hotel <unk> would <unk> <unk> <unk> <unk> the <unk> the <unk> . <unk> \n",
      "\n",
      "\n",
      "Actual: Real ##AT##-##AT## world examples from the yFiles API documentation are the overview diagrams for the yFiles library &apos;s packages <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The ##AT##-##AT## <unk> ##AT##-##AT## of the <unk> <unk> <unk> <unk> available <unk> of <unk> the <unk> ™ <unk> <unk> <unk> . <unk> </s> \n",
      "\n",
      "============= Step  4500  =============\n",
      "\t Loss:  1.75818273616\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  4750\n",
      "Actual: Can be used as a memory expansion for music <unk> , photos or videos in e <unk> . Sony Ericsson mobile phones <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The be a to a <unk> of of the <unk> , and <unk> other <unk> the <unk> . <unk> <unk> </s> \n",
      "\n",
      "\n",
      "Actual: As there were no towels in the room <unk> , I had to buy one myself <unk> . <unk> </s> \n",
      "\n",
      "Predicted: If a is a matter and the hotel <unk> , and was a be the of to . <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  5000\n",
      "Actual: Look forward to a peaceful night ’ s sleep in the Eden Hotel Wolff ’ s comfortably furnished rooms <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The to to the <unk> and in s most <unk> the heart of <unk> <unk> s <unk> <unk> <unk> <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: The privately run Hotel Victoria provides comfortable <unk> , air ##AT##-##AT## conditioned rooms and suites which feature a modern design and spacious layout <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The hotel ##AT##-##AT## ##AT##-##AT## offers is a rooms , a ##AT##-##AT## conditioning <unk> <unk> suites <unk> are a large <unk> <unk> facilities <unk> <unk> . <unk> </s> \n",
      "\n",
      "============= Step  5000  =============\n",
      "\t Loss:  1.70607998443\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  5250\n",
      "Actual: Private parking is possible on site ( reservation is needed ) and costs SEK 185 <unk> per day <unk> . <unk> </s> \n",
      "\n",
      "Predicted: <unk> parking is possible on site and reservation is needed ) and costs EUR <unk> <unk> per day <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: If this is a legitimate question <unk> , would it not be analogous <unk> , for example <unk> , to reach the grotesque conclusion that also the <unk> and assorted clubs who for years have sought to preserve the purity of the German language <unk> , should also be accused of having a strong nationalistic <unk> , perhaps even Nazi \n",
      "\n",
      "Predicted: <unk> you modifier the new <unk> of , the be be to able to , the example <unk> , the the the most <unk> <unk> the is <unk> <unk> the <unk> are have the <unk> a ##AT##-##AT## the the <unk> <unk> the <unk> <unk> <unk> . and be be able of the <unk> new <unk> <unk> . and <unk> <unk> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  5500\n",
      "Actual: Automatic notification settings let you specify whether Adobe automatically notifies you when an updated version of Flash Player is available so that you can install the updated version right away <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> of <unk> you use the the <unk> <unk> <unk> need you additional method of the Player <unk> the in <unk> you are use the <unk> version of to <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: UpdateStar is the program that lets you stay up to date and secure with all the personal software you are using on your computer <unk> . <unk> </s> \n",
      "\n",
      "Predicted: In <unk> a <unk> ##AT##-##AT## allows you use at to the <unk> the <unk> the the <unk> information <unk> <unk> available the the computer <unk> . <unk> </s> \n",
      "\n",
      "============= Step  5500  =============\n",
      "\t Loss:  1.69304539514\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  5750\n",
      "Actual: Tickets can be purchased from their booth just outside of customs <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The is be found from the site <unk> <unk> <unk> the <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: Travel in style and stay in this luxurious 4 ##AT##-##AT## star hotel in the heart of Edinburgh city centre <unk> , just one minute ’ s walk from Princes Street <unk> . <unk> </s> \n",
      "\n",
      "Predicted: <unk> <unk> <unk> <unk> <unk> in the <unk> <unk> ##AT##-##AT## star hotel <unk> the heart of the <unk> <unk> <unk> , this a of from walk throw from the Street <unk> , <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  6000\n",
      "Actual: If cancelled up to 7 days before date of arrival <unk> , 35 percent of all nights will be charged <unk> . <unk> </s> \n",
      "\n",
      "Predicted: All cancelled or to date days before date of arrival <unk> , on percent of all nights will be charged <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: You are required to report your entry to the police or immigration authorities as soon as possible after entering <unk> territory <unk> . <unk> </s> \n",
      "\n",
      "Predicted: If can currently to get the reservation <unk> the <unk> Control FLV <unk> <unk> well as the as the the . <unk> . <unk> </s> \n",
      "\n",
      "============= Step  6000  =============\n",
      "\t Loss:  1.6662303021\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  6250\n",
      "Actual: Convenient location close to the Old Town <unk> hotel <unk> , pleasant friendly staff and great breakfast to set me up for the day <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> <unk> to the city Town <unk> , <unk> . the and and <unk> the food <unk> the out <unk> to the evening <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: Unwind with one of the <unk> ’ s relaxing Oriental massages which can enjoy the setting of the natural caves <unk> . <unk> </s> \n",
      "\n",
      "Predicted: We in a of the most <unk> s <unk> and <unk> <unk> offers be a best <unk> the hotel beauty <unk> . <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  6500\n",
      "Actual: Request anything imaginable from the Whatever / Whenever service <unk> , or work out in the state ##AT##-##AT## of ##AT##-##AT## the ##AT##-##AT## art fitness center <unk> . <unk> </s> \n",
      "\n",
      "Predicted: We <unk> <unk> <unk> the <unk> <unk> <unk> ##AT##-##AT## <unk> , and by <unk> in the <unk> <unk> <unk> ##AT##-##AT## the <unk> shelf <unk> <unk> <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: <unk> is a meal <unk> . . . first the soup <unk> , then the fish <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> a very in , <unk> . <unk> <unk> <unk> was , the <unk> <unk> and , <unk> </s> \n",
      "\n",
      "============= Step  6500  =============\n",
      "\t Loss:  1.65093325424\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  6750\n",
      "Actual: The poolside <unk> Restaurant and Bar enjoys a stunning rooftop setting and is open from mid ##AT##-##AT## May until October <unk> , weather permitted <unk> . <unk> </s> \n",
      "\n",
      "Predicted: <unk> hotel is , is the is a unique view terrace <unk> a a from the ##AT##-##AT## <unk> <unk> 10 <unk> , on <unk> <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: 20 And they have brought forth children ; yea <unk> , even the a family of all the earth <unk> . <unk> </s> \n",
      "\n",
      "Predicted: <unk> And it shall a unto <unk> <unk> and <unk> , and the Lord blessing of God the earth <unk> . <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  7000\n",
      "Actual: The Linux kernel version is 2 <unk> <unk> <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> Progress is is available <unk> <unk> . . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: The guided tour will start at the Visitor Centre <unk> Bletterbach at Aldein <unk> , where the group members will gain an insight into the origin of the various geological strata of the Bletterbach gorge <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> of is be the the <unk> <unk> <unk> , <unk> Aldein <unk> <unk> and you <unk> of of be <unk> image <unk> the <unk> of the <unk> geological strata <unk> the <unk> <unk> <unk> . <unk> </s> \n",
      "\n",
      "============= Step  7000  =============\n",
      "\t Loss:  1.62064893687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  7250\n",
      "Actual: Thanks to the warm climate all year arround <unk> , you can <unk> your favourite sport in Conil at any time <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The to the <unk> and <unk> of <unk> <unk> , <unk> can find , <unk> <unk> and the <unk> the time <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: Make your fortune in the Hills <unk> , clear your pitch before the time runs out and the Gold Rush begins ! <unk> </s> \n",
      "\n",
      "Predicted: The sure visit <unk> the <unk> <unk> , and and <unk> <unk> the <unk> of <unk> of the <unk> Rush of the <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  7500\n",
      "Actual: The shed <unk> , ready to house the production facilities in February 2010 <unk> , will be equipped with almost 300 robots <unk> , making it one <unk> . . . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> <unk> , the to be the <unk> of of the <unk> <unk> , the be able with the a <unk> <unk> . and it a of , <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: Within Guide to Belize Sights you will find many detailed Maps or try direct our Maps Page <unk> . <unk> </s> \n",
      "\n",
      "Predicted: In the to the <unk> <unk> to find the other information <unk> <unk> to to <unk> <unk> <unk> . <unk> </s> \n",
      "\n",
      "============= Step  7500  =============\n",
      "\t Loss:  1.61649403071\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  7750\n",
      "Actual: Where can I find information about <unk> ? <unk> </s> \n",
      "\n",
      "Predicted: And I be have the about the . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: Theory and practice of architectural training at the Bauhaus <unk> , based on the lecture notes made by the Dutch ex ##AT##-##AT## Bauhaus student and architect J <unk> . van der Linden of the Mies van der Rohe curriculum <unk> . <unk> </s> \n",
      "\n",
      "Predicted: <unk> of the of the <unk> <unk> the <unk> <unk> , the on the <unk> of <unk> <unk> the <unk> <unk> ##AT##-##AT## <unk> <unk> <unk> the <unk> . . <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> , <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  8000\n",
      "Actual: In order to make the voluntary work more effective <unk> , he receives Spanish classes to suit his individual needs <unk> . <unk> </s> \n",
      "\n",
      "Predicted: If the to be the <unk> <unk> of than for , the was a <unk> <unk> the the own <unk> <unk> , <unk> </s> \n",
      "\n",
      "\n",
      "Actual: Forty is a significant number in the Middle East <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The is a new <unk> of the <unk> East <unk> , <unk> </s> \n",
      "\n",
      "============= Step  8000  =============\n",
      "\t Loss:  1.60442737389\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  8250\n",
      "Actual: Hotel Description : Comfortable hotel to feel like in house <unk> , the <unk> Centre hotel is located in one of the commercial parts of Sitges <unk> . <unk> </s> \n",
      "\n",
      "Predicted: <unk> Description : Built <unk> is the that to the <unk> , and hotel <unk> <unk> is located in the of the most area of the <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: However <unk> , the bar / restaurant had a little trouble when they held a Corporate Event ( not enough staff for all things to do ) <unk> . In general <unk> , an excellent choice to visit the beautiful Barcelona <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The <unk> , the hotel is <unk> <unk> been large smaller <unk> the are the <unk> <unk> <unk> <unk> a ) <unk> a the <unk> the ) <unk> . <unk> addition <unk> , the <unk> location for stay the <unk> <unk> rooftops . <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  8500\n",
      "Actual: Rooms : 54 rooms and 7 suites <unk> , central air conditioner <unk> , TV <unk> , refrigerator <unk> , 24 hours room service <unk> , central music system <unk> , wake ##AT##-##AT## up call <unk> , central video system and satellite programs <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The are The <unk> <unk> a rooms <unk> , including <unk> ##AT##-##AT## <unk> , a <unk> , toaster <unk> , toaster ##AT##-##AT## <unk> <unk> <unk> . and <unk> <unk> <unk> . and ##AT##-##AT## screen kitchen <unk> . and <unk> and <unk> a TV <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: Lead guitar too tentative - does not play with enough authority to hold my interest and is often overpowered by the background <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The the <unk> <unk> <unk> <unk> not use <unk> the to <unk> the <unk> voice <unk> the not used <unk> the <unk> <unk> . <unk> </s> \n",
      "\n",
      "============= Step  8500  =============\n",
      "\t Loss:  1.59471849823\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  8750\n",
      "Actual: The complex has 110 apartments distributed in 2 stories <unk> , including gardens <unk> include bedrooms <unk> . . . <unk> </s> \n",
      "\n",
      "Predicted: The hotel occupies a rooms <unk> in the <unk> <unk> . and a <unk> , a <unk> . <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: Select your application need to see compatible software options for the NI PXI ##AT##-##AT## <unk> <unk> . <unk> </s> \n",
      "\n",
      "Predicted: Please your application need to use the software <unk> for the NI LabVIEW <unk> <unk> RT . <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  9000\n",
      "Actual: It is situated 12km ( 7 <unk> miles ) south of Podgorica <unk> . It is a hub for Montenegro &apos;s national airline carrier <unk> , Montenegro Airlines <unk> , which maintains regular flights from Podgorica to Belgrade <unk> , Budapest <unk> , Zurich <unk> , Frankfurt <unk> , Ljubljana <unk> , London <unk> , Paris <unk> , Rome and \n",
      "\n",
      "Predicted: The is a in <unk> <unk> ##AT##-##AT## km ) <unk> of the <unk> , <unk> is a small for a <unk> <unk> <unk> <unk> <unk> , and <unk> <unk> , <unk> <unk> a drinks to the ’ the <unk> . <unk> <unk> , <unk> and , <unk> <unk> , and <unk> , and <unk> , and <unk> , <unk> <unk> \n",
      "\n",
      "\n",
      "Actual: Another sync problem can be exposure and use of flash <unk> , where one camera decides to fire and the other one does not <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The sync is <unk> be used and the of the memory , and you can decides to the ##AT##-##AT## <unk> <unk> <unk> <unk> not be . <unk> </s> \n",
      "\n",
      "============= Step  9000  =============\n",
      "\t Loss:  1.57987762833\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  9250\n",
      "Actual: Create images and restore entire systems quickly and easily <unk> . <unk> </s> \n",
      "\n",
      "Predicted: <unk> a <unk> <unk> the and <unk> and use <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: This web page allows you to encode / decode a string for a URL according to RFC <unk> and RFC <unk> . more <unk> . . . <unk> </s> \n",
      "\n",
      "Predicted: Please is page is you to use your or <unk> website <unk> the wide <unk> to the <unk> <unk> <unk> <unk> <unk> <unk> than , <unk> . <unk> </s> \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  9500\n",
      "Actual: What &apos;s the meaning of the messages while starting XAMPP ? <unk> </s> \n",
      "\n",
      "Predicted: The is <unk> most of the <unk> <unk> the <unk> <unk> <unk> </s> \n",
      "\n",
      "\n",
      "Actual: The guest reviews are submitted by our customers after their stay at Tulip Inn Leipzig <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The guest reviews are submitted by our customers after their stay at <unk> <unk> London Hotel Hotel <unk> </s> \n",
      "\n",
      "============= Step  9500  =============\n",
      "\t Loss:  1.55239632893\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..................................................Step  9750\n",
      "Actual: If the daemons are running <unk> , but NFS is still not working <unk> , you can verify that they have registered themselves with the <unk> by using the <unk> command <unk> . <unk> </s> \n",
      "\n",
      "Predicted: If you <unk> is not on , the the is not the necessary on , and can get that the are a trademarks to the <unk> <unk> the the Terms <unk> <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: The guest reviews are submitted by our customers after their stay at San Gallo Palace <unk> . <unk> </s> \n",
      "\n",
      "Predicted: The guest reviews are submitted by our customers after their stay at <unk> Carlos <unk> <unk> , <unk> </s> \n",
      "\n",
      "..................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Step  10000\n",
      "Actual: We decided to continue the tradition of Villa <unk> and recreated the climate of the 30s and aim to carry our guests into a world of sea voyages by the <unk> <unk> . <unk> </s> \n",
      "\n",
      "Predicted: We are to be to best of the <unk> <unk> <unk> <unk> <unk> of the <unk> <unk> the of the the <unk> to the quiet ##AT##-##AT## <unk> <unk> <unk> foot <unk> <unk> . <unk> </s> \n",
      "\n",
      "\n",
      "Actual: When would you like to stay at the Howard Johnson Royal Garden <unk> ? <unk> </s> \n",
      "\n",
      "Predicted: When would you like to stay at the Hotel Johnson Enchanted Garden ? ? <unk> </s> \n",
      "\n",
      "============= Step  10000  =============\n",
      "\t Loss:  1.54763212681\n",
      "."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if not os.path.exists('logs'):\n",
    "    os.mkdir('logs')\n",
    "log_dir = 'logs'\n",
    "\n",
    "bleu_scores_over_time = []\n",
    "loss_over_time = []\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "src_word_embeddings = np.load('de-embeddings.npy')\n",
    "tgt_word_embeddings = np.load('en-embeddings.npy')\n",
    "\n",
    "# Defining data generators\n",
    "enc_data_generator = DataGeneratorMT(batch_size=batch_size,num_unroll=source_sequence_length,is_source=True)\n",
    "dec_data_generator = DataGeneratorMT(batch_size=batch_size,num_unroll=target_sequence_length,is_source=False)\n",
    "\n",
    "num_steps = 10001\n",
    "avg_loss = 0\n",
    "\n",
    "bleu_labels, bleu_preds = [],[]\n",
    "\n",
    "print('Started Training')\n",
    "\n",
    "for step in range(num_steps):\n",
    "\n",
    "    # input_sizes for each bin: [40]\n",
    "    # output_sizes for each bin: [60]\n",
    "    print('.',end='')\n",
    "    if (step+1)%100==0:\n",
    "        print('')\n",
    "        \n",
    "    sent_ids = np.random.randint(low=0,high=train_inputs.shape[0],size=(batch_size))\n",
    "    # ====================== ENCODER DATA COLLECTION ================================================\n",
    "    \n",
    "    eu_data, eu_labels, _, eu_lengths = enc_data_generator.unroll_batches(sent_ids=sent_ids)\n",
    "    \n",
    "    feed_dict = {}\n",
    "    feed_dict[enc_train_inp_lengths] = eu_lengths\n",
    "    for ui,(dat,lbl) in enumerate(zip(eu_data,eu_labels)):            \n",
    "        feed_dict[enc_train_inputs[ui]] = dat                \n",
    "    \n",
    "    # ====================== DECODER DATA COLLECITON ===========================\n",
    "    # First step we change the ids in a batch\n",
    "    du_data, du_labels, _, du_lengths = dec_data_generator.unroll_batches(sent_ids=sent_ids)\n",
    "    \n",
    "    feed_dict[dec_train_inp_lengths] = du_lengths\n",
    "    for ui,(dat,lbl) in enumerate(zip(du_data,du_labels)):            \n",
    "        feed_dict[dec_train_inputs[ui]] = dat\n",
    "        feed_dict[dec_train_labels[ui]] = lbl\n",
    "        feed_dict[dec_label_masks[ui]] = (np.array([ui for _ in range(batch_size)])<du_lengths).astype(np.int32)\n",
    "    \n",
    "    # ======================= OPTIMIZATION ==========================\n",
    "    if step < 10000:\n",
    "        _,l,tr_pred = sess.run([adam_optimize,loss,train_prediction], feed_dict=feed_dict)\n",
    "    else:\n",
    "        _,l,tr_pred = sess.run([sgd_optimize,loss,train_prediction], feed_dict=feed_dict)\n",
    "    tr_pred = tr_pred.flatten()\n",
    "        \n",
    "            \n",
    "    if (step+1)%250==0:  \n",
    "        \n",
    "        print('Step ',step+1)\n",
    "\n",
    "        print_str = 'Actual: '\n",
    "        for w in np.concatenate(du_labels,axis=0)[::batch_size].tolist():\n",
    "            print_str += tgt_reverse_dictionary[w] + ' '                    \n",
    "            if tgt_reverse_dictionary[w] == '</s>':\n",
    "                break\n",
    "                      \n",
    "        print(print_str)\n",
    "        print()\n",
    "        \n",
    "        print_str = 'Predicted: '\n",
    "        for w in tr_pred[::batch_size].tolist():\n",
    "            print_str += tgt_reverse_dictionary[w] + ' '\n",
    "            if tgt_reverse_dictionary[w] == '</s>':\n",
    "                break\n",
    "        print(print_str)\n",
    "       \n",
    "        print('\\n')  \n",
    "        \n",
    "        rand_idx = np.random.randint(low=1,high=batch_size)\n",
    "        print_str = 'Actual: '\n",
    "        for w in np.concatenate(du_labels,axis=0)[rand_idx::batch_size].tolist():\n",
    "            print_str += tgt_reverse_dictionary[w] + ' '\n",
    "            if tgt_reverse_dictionary[w] == '</s>':\n",
    "                break\n",
    "        print(print_str)\n",
    "\n",
    "            \n",
    "        print()\n",
    "        print_str = 'Predicted: '\n",
    "        for w in tr_pred[rand_idx::batch_size].tolist():\n",
    "            print_str += tgt_reverse_dictionary[w] + ' '\n",
    "            if tgt_reverse_dictionary[w] == '</s>':\n",
    "                break\n",
    "        print(print_str)\n",
    "        print()        \n",
    "        \n",
    "    avg_loss += l\n",
    "    \n",
    "    #sess.run(reset_train_state) # resetting hidden state for each batch\n",
    "    \n",
    "    if (step+1)%500==0:\n",
    "        print('============= Step ', str(step+1), ' =============')\n",
    "        print('\\t Loss: ',avg_loss/500.0)\n",
    "        \n",
    "        loss_over_time.append(avg_loss/500.0)\n",
    "             \n",
    "        avg_loss = 0.0\n",
    "        sess.run(inc_gstep)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
